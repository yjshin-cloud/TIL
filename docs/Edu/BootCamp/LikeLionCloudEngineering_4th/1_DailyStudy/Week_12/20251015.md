# AWS ìŠ¤í† ë¦¬ì§€ ì™„ë²½ ê°€ì´ë“œ ğŸ—„ï¸

> ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” AWS ìŠ¤í† ë¦¬ì§€ ì„¤ëª…ì„œ

---

## ğŸ“š ëª©ì°¨

1. [ìŠ¤í† ë¦¬ì§€ë€ ë¬´ì—‡ì¸ê°€ìš”?](#1-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80%EC%9A%94)
2. [ê°ì²´ ìŠ¤í† ë¦¬ì§€ - Amazon S3](#2-%EA%B0%9D%EC%B2%B4-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80---amazon-s3)
3. [íŒŒì¼ ìŠ¤í† ë¦¬ì§€ - EFS & FSx](#3-%ED%8C%8C%EC%9D%BC-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80---efs--fsx)
4. [ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬](#4-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%A7%88%EC%9D%B4%EA%B7%B8%EB%A0%88%EC%9D%B4%EC%85%98-%EB%8F%84%EA%B5%AC)
5. [í˜„ì—… í™œìš© ê°€ì´ë“œ](#5-%ED%98%84%EC%97%85-%ED%99%9C%EC%9A%A9-%EA%B0%80%EC%9D%B4%EB%93%9C)

---

## 1. ìŠ¤í† ë¦¬ì§€ë€ ë¬´ì—‡ì¸ê°€ìš”?

### ğŸ¯ ì‰½ê²Œ ì´í•´í•˜ê¸°

ìŠ¤í† ë¦¬ì§€ëŠ” **ë””ì§€í„¸ ì°½ê³ **ë¼ê³  ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤. ì§‘ì— ë¬¼ê±´ì„ ë³´ê´€í•˜ëŠ” ë°©ë²•ì´ ì—¬ëŸ¬ ê°€ì§€ì¸ ê²ƒì²˜ëŸ¼, í´ë¼ìš°ë“œì—ì„œë„ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°©ë²•ì´ ì—¬ëŸ¬ ê°€ì§€ì˜ˆìš”.


```mermaid
graph TB
    A[í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€] --> B[ë¸”ë¡ ìŠ¤í† ë¦¬ì§€]
    A --> C[íŒŒì¼ ìŠ¤í† ë¦¬ì§€]
    A --> D[ê°ì²´ ìŠ¤í† ë¦¬ì§€]
    
    B --> B1["í•˜ë“œë””ìŠ¤í¬ì²˜ëŸ¼<br/>ë¹ ë¥´ê³  ì§ì ‘ ì—°ê²°"]
    B --> B2["ì˜ˆ: EBS"]
    
    C --> C1["í´ë”ì²˜ëŸ¼<br/>ì—¬ëŸ¬ ì‚¬ëŒì´ ê³µìœ "]
    C --> C2["ì˜ˆ: EFS, FSx"]
    
    D --> D1["ì‚¬ì§„ì²©ì²˜ëŸ¼<br/>ë§ì€ íŒŒì¼ ë³´ê´€"]
    D --> D2["ì˜ˆ: S3"]
    
    style A fill:#ff9999
    style B fill:#99ccff
    style C fill:#99ff99
    style D fill:#ffcc99
```

### ğŸ“ ìŠ¤í† ë¦¬ì§€ ìœ í˜• ë¹„êµ

|ìœ í˜•|ì‹¤ìƒí™œ ë¹„ìœ |AWS ì„œë¹„ìŠ¤|ì–¸ì œ ì‚¬ìš©?|
|---|---|---|---|
|**ë¸”ë¡ ìŠ¤í† ë¦¬ì§€**|ì»´í“¨í„° í•˜ë“œë””ìŠ¤í¬|EBS|í”„ë¡œê·¸ë¨ì´ ë¹ ë¥´ê²Œ ì½ê³  ì“¸ ë•Œ|
|**íŒŒì¼ ìŠ¤í† ë¦¬ì§€**|ê³µìœ  í´ë” (NAS)|EFS, FSx|ì—¬ëŸ¬ ì»´í“¨í„°ê°€ ê°™ì´ ì“¸ ë•Œ|
|**ê°ì²´ ìŠ¤í† ë¦¬ì§€**|ì‚¬ì§„ ì•¨ë²”, ì°½ê³ |S3|ë§ì€ íŒŒì¼ì„ ì˜¤ë˜ ë³´ê´€í•  ë•Œ|

---

## 2. ê°ì²´ ìŠ¤í† ë¦¬ì§€ - Amazon S3

### ğŸ¨ S3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

**S3 = Simple Storage Service** (ê°„ë‹¨í•œ ì €ì¥ì†Œ ì„œë¹„ìŠ¤)

ì‚¬ì§„, ë™ì˜ìƒ, ë¬¸ì„œ ë“±ì„ **ë¬´ì œí•œìœ¼ë¡œ ì €ì¥**í•  ìˆ˜ ìˆëŠ” ì¸í„°ë„· ì°½ê³ ì˜ˆìš”!


```mermaid
graph LR
    A[ì‚¬ìš©ì] -->|íŒŒì¼ ì—…ë¡œë“œ| B[S3 ë²„í‚·]
    B -->|ì €ì¥| C[ê°ì²´ 1]
    B -->|ì €ì¥| D[ê°ì²´ 2]
    B -->|ì €ì¥| E[ê°ì²´ 3]
    
    C -.->|ë©”íƒ€ë°ì´í„°| C1[íŒŒì¼ëª…: photo.jpg<br/>í¬ê¸°: 2MB<br/>ë‚ ì§œ: 2025-10-15]
    
    style B fill:#ff9900
    style C fill:#ffcc99
    style D fill:#ffcc99
    style E fill:#ffcc99
```

### ğŸ—ï¸ S3ì˜ í•µì‹¬ êµ¬ì„±ìš”ì†Œ


```mermaid
graph TD
    A[S3 ì „ì²´ ì‹œìŠ¤í…œ] --> B[ë²„í‚· Bucket]
    B --> C[ê°ì²´ Object]
    C --> D[í‚¤ Key]
    C --> E[ê°’ Value]
    C --> F[ë©”íƒ€ë°ì´í„°]
    
    B -.->|ì˜ˆì‹œ| B1["my-photo-bucket<br/>(ì „ ì„¸ê³„ì—ì„œ ìœ ì¼í•œ ì´ë¦„)"]
    D -.->|ì˜ˆì‹œ| D1["2025/photos/vacation.jpg<br/>(íŒŒì¼ ê²½ë¡œ)"]
    E -.->|ì˜ˆì‹œ| E1["ì‹¤ì œ ì‚¬ì§„ íŒŒì¼ ë°ì´í„°"]
    F -.->|ì˜ˆì‹œ| F1["íŒŒì¼ í¬ê¸°, ì—…ë¡œë“œ ë‚ ì§œ<br/>ì‚¬ìš©ì ì •ì˜ íƒœê·¸"]
    
    style A fill:#ff6666
    style B fill:#ff9999
    style C fill:#ffcccc
```

#### ì‹¤ì œ ì½”ë“œë¡œ ì´í•´í•˜ê¸°


```python
# Pythonìœ¼ë¡œ S3ì— íŒŒì¼ ì—…ë¡œë“œí•˜ê¸°
import boto3

# S3 ì—°ê²° ì¤€ë¹„ (AWSì™€ ì—°ê²°í•˜ëŠ” ë„êµ¬)
s3 = boto3.client('s3')

# íŒŒì¼ ì—…ë¡œë“œ
s3.upload_file(
    'my_photo.jpg',           # ë‚´ ì»´í“¨í„°ì˜ íŒŒì¼
    'my-photo-bucket',        # S3 ë²„í‚· ì´ë¦„ (ì°½ê³  ì´ë¦„)
    '2025/photos/vacation.jpg' # S3ì— ì €ì¥ë  ê²½ë¡œ (Key)
)

# âœ… ì´ë ‡ê²Œ í•˜ë©´ íŒŒì¼ì´ í´ë¼ìš°ë“œì— ì €ì¥ë©ë‹ˆë‹¤!
```

### ğŸ’° S3 ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ (ì €ì¥ ë°©ë²• ì„ íƒí•˜ê¸°)

**ë¹„ìœ **: ì§‘ì— ë¬¼ê±´ì„ ë³´ê´€í•  ë•Œë„ ë°©ë²•ì´ ë‹¬ë¼ìš”

- ìì£¼ ì“°ëŠ” ë¬¼ê±´ â†’ ì±…ìƒ ìœ„ (ë¹ ë¥´ì§€ë§Œ ê³µê°„ ì°¨ì§€)
- ê°€ë” ì“°ëŠ” ë¬¼ê±´ â†’ ì„œë (ì¤‘ê°„)
- ê±°ì˜ ì•ˆ ì“°ëŠ” ë¬¼ê±´ â†’ ì°½ê³  (ëŠë¦¬ì§€ë§Œ ì €ë ´)


```mermaid
graph TB
    A[S3 ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤] --> B[Standard<br/>í‘œì¤€]
    A --> C[Standard-IA<br/>ìì£¼ ì•ˆì”€]
    A --> D[One Zone-IA<br/>í•œ ê³³ì—ë§Œ]
    A --> E[Glacier<br/>ì•„ì¹´ì´ë¸Œ]
    A --> F[Intelligent-Tiering<br/>ìë™ ê´€ë¦¬]
    
    B -.->|íŠ¹ì§•| B1["ğŸ’¸ ë¹„ìš©: ë†’ìŒ<br/>âš¡ ì†ë„: ë¹ ë¦„<br/>ğŸ“Š ì‚¬ìš©: ë§¤ì¼"]
    C -.->|íŠ¹ì§•| C1["ğŸ’¸ ë¹„ìš©: ì¤‘ê°„<br/>âš¡ ì†ë„: ë¹ ë¦„<br/>ğŸ“Š ì‚¬ìš©: ì›” 1-2íšŒ"]
    D -.->|íŠ¹ì§•| D1["ğŸ’¸ ë¹„ìš©: ì €ë ´<br/>âš¡ ì†ë„: ë¹ ë¦„<br/>âš ï¸ ìœ„í—˜: í•œ ê³³ë§Œ ì €ì¥"]
    E -.->|íŠ¹ì§•| E1["ğŸ’¸ ë¹„ìš©: ë§¤ìš° ì €ë ´<br/>â° ì†ë„: ëŠë¦¼<br/>ğŸ“¦ ì‚¬ìš©: ê±°ì˜ ì•ˆë´„"]
    F -.->|íŠ¹ì§•| F1["ğŸ¤– ìë™ìœ¼ë¡œ<br/>ì ì ˆí•œ ê³³ìœ¼ë¡œ ì´ë™"]
    
    style B fill:#ff6666
    style C fill:#ff9999
    style D fill:#ffcc99
    style E fill:#99ccff
    style F fill:#99ff99
```

#### ğŸ“Š ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìƒì„¸ ë¹„êµ

|í´ë˜ìŠ¤|ì›” ë¹„ìš© (1GB ê¸°ì¤€)|êº¼ë‚´ëŠ” ì‹œê°„|ì–¸ì œ ì‚¬ìš©?|ì‹¤ìƒí™œ ì˜ˆì‹œ|
|---|---|---|---|---|
|**Standard**|$0.023|ì¦‰ì‹œ|ë§¤ì¼ ë³´ëŠ” íŒŒì¼|ì›¹ì‚¬ì´íŠ¸ ì´ë¯¸ì§€|
|**Standard-IA**|$0.0125|ì¦‰ì‹œ|ê°€ë” ë³´ëŠ” íŒŒì¼|ì›”ë³„ ë³´ê³ ì„œ|
|**One Zone-IA**|$0.01|ì¦‰ì‹œ|ë‹¤ì‹œ ë§Œë“¤ ìˆ˜ ìˆëŠ” íŒŒì¼|ì„ì‹œ ë°±ì—…|
|**Glacier Instant**|$0.004|ì¦‰ì‹œ|ìì£¼ëŠ” ì•„ë‹ˆì§€ë§Œ ê¸‰í•  ìˆ˜ ìˆìŒ|ë¶„ê¸°ë³„ ìë£Œ|
|**Glacier Flexible**|$0.0036|1ë¶„~5ì‹œê°„|ê±°ì˜ ì•ˆ ë´„|ì˜¤ë˜ëœ ë¡œê·¸|
|**Glacier Deep Archive**|$0.00099|12ì‹œê°„|ë²•ì  ë³´ê´€ìš©|7ë…„ì¹˜ ì„¸ê¸ˆ ìë£Œ|

#### ğŸ’¡ í˜„ì—… íŒ: ì–´ë–¤ í´ë˜ìŠ¤ë¥¼ ì„ íƒí•´ì•¼ í• ê¹Œ?


```python
# ì‹¤ì œ í˜„ì—…ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìˆ˜ëª…ì£¼ê¸° ì •ì±… ì˜ˆì‹œ
lifecycle_policy = {
    "Rules": [
        {
            "Id": "ìë™ ë¹„ìš© ì ˆê° ê·œì¹™",
            "Status": "Enabled",
            "Transitions": [
                {
                    # 30ì¼ í›„: ìì£¼ ì•ˆ ì“°ëŠ” ì €ì¥ì†Œë¡œ ì´ë™
                    "Days": 30,
                    "StorageClass": "STANDARD_IA"
                },
                {
                    # 90ì¼ í›„: ì•„ì¹´ì´ë¸Œë¡œ ì´ë™
                    "Days": 90,
                    "StorageClass": "GLACIER"
                }
            ],
            "Expiration": {
                # 365ì¼ í›„: ì‚­ì œ
                "Days": 365
            }
        }
    ]
}

# âœ… ì´ë ‡ê²Œ ì„¤ì •í•˜ë©´ ìë™ìœ¼ë¡œ ë¹„ìš©ì´ ì ˆê°ë©ë‹ˆë‹¤!
# 30ì¼ ì§€ë‚œ íŒŒì¼: 50% ì ˆì•½
# 90ì¼ ì§€ë‚œ íŒŒì¼: 84% ì ˆì•½
```

### ğŸ”„ ë²„ì „ ê´€ë¦¬ (Versioning)

**ë¹„ìœ **: ì›Œë“œ ë¬¸ì„œì˜ "ë³€ê²½ ë‚´ìš© ì¶”ì " ê¸°ëŠ¥ê³¼ ê°™ì•„ìš”!


```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant S3 as S3 ë²„í‚·
    
    User->>S3: report.pdf ì—…ë¡œë“œ (ë²„ì „ 1)
    Note over S3: Version ID: abc123
    
    User->>S3: report.pdf ìˆ˜ì • í›„ ì—…ë¡œë“œ (ë²„ì „ 2)
    Note over S3: Version ID: def456<br/>âš ï¸ ë²„ì „ 1ì€ ê·¸ëŒ€ë¡œ ìœ ì§€!
    
    User->>S3: report.pdf ì‚­ì œ
    Note over S3: Delete Marker ìƒì„±<br/>âš ï¸ ì‹¤ì œë¡œëŠ” ì‚­ì œ ì•ˆë¨!
    
    User->>S3: ë²„ì „ 1 ë³µêµ¬ ìš”ì²­
    S3-->>User: report.pdf (ë²„ì „ 1) ë³µì›
```

#### ì½”ë“œë¡œ ë²„ì „ ê´€ë¦¬ í™œìš©í•˜ê¸°


```python
import boto3

s3 = boto3.client('s3')

# 1ï¸âƒ£ ë²„ì „ ê´€ë¦¬ í™œì„±í™”
s3.put_bucket_versioning(
    Bucket='my-bucket',
    VersioningConfiguration={'Status': 'Enabled'}
)

# 2ï¸âƒ£ íŠ¹ì • ë²„ì „ ê°€ì ¸ì˜¤ê¸°
response = s3.get_object(
    Bucket='my-bucket',
    Key='report.pdf',
    VersionId='abc123'  # ì´ì „ ë²„ì „ ID
)

# 3ï¸âƒ£ ëª¨ë“  ë²„ì „ ëª©ë¡ ë³´ê¸°
versions = s3.list_object_versions(
    Bucket='my-bucket',
    Prefix='report.pdf'
)

# âœ… ì‹¤ìˆ˜ë¡œ ì‚­ì œí•´ë„ ë³µêµ¬ ê°€ëŠ¥!
```

### ğŸ” S3 ë³´ì•ˆ ë° ê¶Œí•œ ê´€ë¦¬

mermaid

```mermaid
graph TD
    A[S3 ë³´ì•ˆ ê³„ì¸µ] --> B[IAM ì •ì±…]
    A --> C[ë²„í‚· ì •ì±…]
    A --> D[ACL]
    A --> E[ì•”í˜¸í™”]
    
    B -.->|ëˆ„ê°€| B1["íŠ¹ì • ì‚¬ìš©ì/ì—­í• ë§Œ<br/>ì ‘ê·¼ ê°€ëŠ¥"]
    C -.->|ë¬´ì—‡ì„| C1["ë²„í‚· ì „ì²´ ë˜ëŠ”<br/>íŠ¹ì • í´ë”ë§Œ ê³µê°œ"]
    D -.->|ê°œë³„| D1["íŒŒì¼ í•˜ë‚˜í•˜ë‚˜<br/>ê¶Œí•œ ì„¤ì •"]
    E -.->|ë³´í˜¸| E1["ì €ì¥/ì „ì†¡ ì‹œ<br/>ì•”í˜¸í™”"]
    
    style A fill:#ff6666
    style B fill:#99ccff
    style C fill:#99ff99
    style D fill:#ffcc99
    style E fill:#ff9999
```

#### ì‹¤ì „ ë³´ì•ˆ ì„¤ì • ì˜ˆì‹œ


```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "ì›¹ì‚¬ì´íŠ¸ ì´ë¯¸ì§€ ê³µê°œ",
      "Effect": "Allow",
      "Principal": "*",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-website-bucket/images/*"
    },
    {
      "Sid": "ê´€ë¦¬ìë§Œ ì—…ë¡œë“œ ê°€ëŠ¥",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::123456789012:user/admin"
      },
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::my-website-bucket/*"
    }
  ]
}
```

**ì„¤ëª…**:

- ì²« ë²ˆì§¸ ê·œì¹™: ëˆ„êµ¬ë‚˜ images í´ë”ì˜ ì‚¬ì§„ì„ ë³¼ ìˆ˜ ìˆìŒ
- ë‘ ë²ˆì§¸ ê·œì¹™: admin ì‚¬ìš©ìë§Œ íŒŒì¼ì„ ì˜¬ë¦´ ìˆ˜ ìˆìŒ

### ğŸš€ S3 ê³ ê¸‰ ê¸°ëŠ¥

#### 1. ì •ì  ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…


```mermaid
graph LR
    A[ì›¹ ë¸Œë¼ìš°ì €] -->|http ìš”ì²­| B[S3 ë²„í‚·]
    B -->|HTML ì „ì†¡| A
    B --> C[index.html]
    B --> D[style.css]
    B --> E[images/]
    
    style B fill:#ff9900
```


```html
<!-- index.html ì˜ˆì‹œ -->
<!DOCTYPE html>
<html>
<head>
    <title>ë‚´ ì²« S3 ì›¹ì‚¬ì´íŠ¸</title>
</head>
<body>
    <h1>ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘‹</h1>
    <p>ì´ í˜ì´ì§€ëŠ” S3ì—ì„œ í˜¸ìŠ¤íŒ…ë©ë‹ˆë‹¤.</p>
    <img src="images/photo.jpg" alt="ì‚¬ì§„">
</body>
</html>

<!-- 
âœ… ì´ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œí•˜ê³  
   "ì •ì  ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…"ì„ í™œì„±í™”í•˜ë©´
   ì›¹ì‚¬ì´íŠ¸ê°€ ì™„ì„±ë©ë‹ˆë‹¤!
-->
```

#### 2. ì´ë²¤íŠ¸ ì•Œë¦¼


```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant S3 as S3 ë²„í‚·
    participant Lambda as Lambda í•¨ìˆ˜
    participant SNS as ì´ë©”ì¼ ì•Œë¦¼
    
    User->>S3: ì‚¬ì§„ ì—…ë¡œë“œ
    S3->>Lambda: ì´ë²¤íŠ¸ ë°œìƒ!
    Lambda->>Lambda: ì¸ë„¤ì¼ ìƒì„±
    Lambda->>S3: ì¸ë„¤ì¼ ì €ì¥
    Lambda->>SNS: ì™„ë£Œ ì•Œë¦¼
    SNS->>User: ğŸ“§ ì´ë©”ì¼ ì „ì†¡
```


```python
# Lambda í•¨ìˆ˜ ì˜ˆì‹œ (ìë™ ì¸ë„¤ì¼ ìƒì„±)
import boto3
from PIL import Image
import io

def lambda_handler(event, context):
    # S3ì—ì„œ ì—…ë¡œë“œëœ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    
    # ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    s3 = boto3.client('s3')
    response = s3.get_object(Bucket=bucket, Key=key)
    image = Image.open(response['Body'])
    
    # ì¸ë„¤ì¼ ìƒì„± (200x200 í¬ê¸°ë¡œ)
    image.thumbnail((200, 200))
    
    # ì¸ë„¤ì¼ ì €ì¥
    buffer = io.BytesIO()
    image.save(buffer, 'JPEG')
    buffer.seek(0)
    
    # S3ì— ì¸ë„¤ì¼ ì—…ë¡œë“œ
    thumbnail_key = f"thumbnails/{key}"
    s3.put_object(
        Bucket=bucket,
        Key=thumbnail_key,
        Body=buffer,
        ContentType='image/jpeg'
    )
    
    # âœ… ì‚¬ì§„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì¸ë„¤ì¼ì´ ìƒì„±ë©ë‹ˆë‹¤!
    return {'statusCode': 200}
```

---

## 3. íŒŒì¼ ìŠ¤í† ë¦¬ì§€ - EFS & FSx

### ğŸ“ EFS (Elastic File System)

**ë¹„ìœ **: í•™êµ ê³µìœ  í´ë”ì²˜ëŸ¼ ì—¬ëŸ¬ ì»´í“¨í„°ê°€ ë™ì‹œì— ê°™ì€ í´ë”ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”!


```mermaid
graph TD
    A[EFS íŒŒì¼ ì‹œìŠ¤í…œ] --> B[EC2 ì¸ìŠ¤í„´ìŠ¤ 1]
    A --> C[EC2 ì¸ìŠ¤í„´ìŠ¤ 2]
    A --> D[EC2 ì¸ìŠ¤í„´ìŠ¤ 3]
    
    B -.->|ë™ì‹œì—| E["/shared/data"]
    C -.->|ì ‘ê·¼| E
    D -.->|ê°€ëŠ¥| E
    
    E --> F[íŒŒì¼1.txt]
    E --> G[íŒŒì¼2.jpg]
    E --> H[í´ë”/]
    
    style A fill:#99ff99
    style B fill:#99ccff
    style C fill:#99ccff
    style D fill:#99ccff
```

#### EFS ì‚¬ìš© ì˜ˆì‹œ


```bash
# EC2 ì¸ìŠ¤í„´ìŠ¤ì— EFS ë§ˆìš´íŠ¸í•˜ê¸°

# 1ï¸âƒ£ í•„ìš”í•œ ë„êµ¬ ì„¤ì¹˜
sudo yum install -y amazon-efs-utils

# 2ï¸âƒ£ ë§ˆìš´íŠ¸ í¬ì¸íŠ¸ ìƒì„±
sudo mkdir /mnt/efs

# 3ï¸âƒ£ EFS ì—°ê²°
sudo mount -t efs fs-12345678:/ /mnt/efs

# 4ï¸âƒ£ ì´ì œ /mnt/efs í´ë”ë¥¼ ì—¬ëŸ¬ ì„œë²„ê°€ ê³µìœ í•©ë‹ˆë‹¤!
cd /mnt/efs
echo "ì•ˆë…•í•˜ì„¸ìš”" > shared_file.txt

# âœ… ë‹¤ë¥¸ EC2ì—ì„œë„ ì´ íŒŒì¼ì„ ë³¼ ìˆ˜ ìˆì–´ìš”!
```

### ğŸ¢ FSx (ë‹¤ì–‘í•œ íŒŒì¼ ì‹œìŠ¤í…œ)


```mermaid
graph TB
    A[FSx íŒ¨ë°€ë¦¬] --> B[FSx for Windows]
    A --> C[FSx for Lustre]
    A --> D[FSx for NetApp ONTAP]
    A --> E[FSx for OpenZFS]
    
    B -.->|ìš©ë„| B1["Windows ì„œë²„<br/>íŒŒì¼ ê³µìœ <br/>Active Directory"]
    C -.->|ìš©ë„| C1["ë¨¸ì‹ ëŸ¬ë‹<br/>ê³ ì„±ëŠ¥ ì»´í“¨íŒ…<br/>ëŒ€ìš©ëŸ‰ ë¶„ì„"]
    D -.->|ìš©ë„| D1["ê¸°ì—…ìš© NAS<br/>í•˜ì´ë¸Œë¦¬ë“œ í´ë¼ìš°ë“œ<br/>SAP, Oracle"]
    E -.->|ìš©ë„| E1["Linux/Unix<br/>DevOps<br/>ìŠ¤ëƒ…ìƒ· ê´€ë¦¬"]
    
    style A fill:#ff6666
    style B fill:#99ccff
    style C fill:#99ff99
    style D fill:#ffcc99
    style E fill:#ff9999
```

### ğŸ“Š EFS vs FSx vs EBS vs S3 ë¹„êµ


```mermaid
graph TB
    A[ì €ì¥ì†Œ ì„ íƒ ê°€ì´ë“œ] --> B{ì—¬ëŸ¬ ì„œë²„ê°€<br/>ë™ì‹œ ì ‘ê·¼?}
    
    B -->|Yes| C{ì–´ë–¤ OS?}
    B -->|No| D{ë¬´ì—‡ì„ ì €ì¥?}
    
    C -->|Linux| E[EFS ì¶”ì²œ]
    C -->|Windows| F[FSx for Windows]
    C -->|ê³ ì„±ëŠ¥ í•„ìš”| G[FSx for Lustre]
    
    D -->|ë””ìŠ¤í¬<br/>ë°ì´í„°ë² ì´ìŠ¤| H[EBS ì¶”ì²œ]
    D -->|íŒŒì¼<br/>ë°±ì—…| I[S3 ì¶”ì²œ]
    
    style E fill:#99ff99
    style F fill:#99ccff
    style G fill:#ff9999
    style H fill:#ffcc99
    style I fill:#ff9900
```

|ê¸°ì¤€|EBS|EFS|FSx|S3|
|---|---|---|---|---|
|**ì—°ê²° ë°©ì‹**|1:1 (í•œ ì„œë²„ë§Œ)|N:N (ì—¬ëŸ¬ ì„œë²„)|N:N (ì—¬ëŸ¬ ì„œë²„)|HTTP/API|
|**ì‚¬ìš© ì˜ˆ**|ë°ì´í„°ë² ì´ìŠ¤|ì›¹ì„œë²„ ê³µìœ |Windows ê³µìœ |ë°±ì—…, ì´ë¯¸ì§€|
|**í™•ì¥ì„±**|ìˆ˜ë™|ìë™|ìˆ˜ë™|ë¬´ì œí•œ|
|**ë¹„ìš©**|ì¤‘ê°„|ë†’ìŒ|ë†’ìŒ|ì €ë ´|
|**ì†ë„**|ë§¤ìš° ë¹ ë¦„|ë¹ ë¦„|ë§¤ìš° ë¹ ë¦„|ë³´í†µ|

---

## 4. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ë„êµ¬

### ğŸšš ë°ì´í„°ë¥¼ í´ë¼ìš°ë“œë¡œ ì˜®ê¸°ëŠ” ë°©ë²•


```mermaid
graph TD
    A[ì˜¨í”„ë ˆë¯¸ìŠ¤<br/>ë°ì´í„°ì„¼í„°] --> B{ë°ì´í„° í¬ê¸°}
    
    B -->|ì‘ìŒ<br/>1TB ì´í•˜| C[ì¸í„°ë„· ì§ì ‘ ì „ì†¡]
    B -->|ì¤‘ê°„<br/>1TB~50TB| D[AWS DataSync]
    B -->|í¼<br/>50TB~PB| E[AWS Snowball]
    B -->|ì´ˆëŒ€í˜•<br/>EBê¸‰| F[AWS Snowmobile]
    
    C --> G[S3, EFSë¡œ ì—…ë¡œë“œ]
    D --> G
    E --> H[ë¬¼ë¦¬ì  ì¥ë¹„ ë°°ì†¡]
    F --> H
    
    style A fill:#ff6666
    style C fill:#99ff99
    style D fill:#99ccff
    style E fill:#ffcc99
    style F fill:#ff9999
```

### ğŸŒ‰ Storage Gateway (í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤í† ë¦¬ì§€)

**ë¹„ìœ **: ì§‘ê³¼ ì‚¬ë¬´ì‹¤ì„ ì—°ê²°í•˜ëŠ” ë‹¤ë¦¬ ê°™ì€ ì—­í• !


```mermaid
graph LR
    A[ì˜¨í”„ë ˆë¯¸ìŠ¤<br/>ë°ì´í„°ì„¼í„°] -->|ë„¤íŠ¸ì›Œí¬| B[Storage Gateway]
    B -->|ì•”í˜¸í™” ì „ì†¡| C[AWS í´ë¼ìš°ë“œ]
    
    B --> B1[File Gateway]
    B --> B2[Volume Gateway]
    B --> B3[Tape Gateway]
    
    B1 -.->|NFS/SMB| D[S3 ë²„í‚·]
    B2 -.->|iSCSI| E[EBS ìŠ¤ëƒ…ìƒ·]
    B3 -.->|ê°€ìƒ í…Œì´í”„| F[S3 Glacier]
    
    style A fill:#ff9999
    style B fill:#99ccff
    style C fill:#99ff99
```

#### Storage Gateway ì‚¬ìš© ì˜ˆì‹œ


```python
# File Gateway ì„¤ì • (Python SDK)
import boto3

# Storage Gateway í´ë¼ì´ì–¸íŠ¸ ìƒì„±
sg = boto3.client('storagegateway')

# File Gateway ìƒì„±
response = sg.create_nfs_file_share(
    GatewayARN='arn:aws:storagegateway:...',
    LocationARN='arn:aws:s3:::my-backup-bucket',
    Role='arn:aws:iam::...:role/StorageGatewayRole',
    ClientList=['0.0.0.0/0'],  # ì ‘ê·¼ í—ˆìš© IP
    DefaultStorageClass='S3_STANDARD_IA'  # ì €ì¥ í´ë˜ìŠ¤
)

# âœ… ì´ì œ ì˜¨í”„ë ˆë¯¸ìŠ¤ì—ì„œ S3ë¥¼ ë¡œì»¬ í´ë”ì²˜ëŸ¼ ì‚¬ìš© ê°€ëŠ¥!
```

### âš¡ AWS DataSync (ê³ ì† ë°ì´í„° ì „ì†¡)


```mermaid
sequenceDiagram
    participant On as ì˜¨í”„ë ˆë¯¸ìŠ¤<br/>NFS ì„œë²„
    participant Agent as DataSync<br/>ì—ì´ì „íŠ¸
    participant AWS as AWS<br/>S3/EFS
    
    On->>Agent: 1. íŒŒì¼ ìŠ¤ìº”
    Agent->>Agent: 2. ë³€ê²½ëœ íŒŒì¼ë§Œ ì„ íƒ
    Agent->>AWS: 3. ì•”í˜¸í™” ì „ì†¡ (10ë°° ë¹ ë¦„)
    AWS->>AWS: 4. ë¬´ê²°ì„± ê²€ì¦
    AWS-->>Agent: 5. ì™„ë£Œ ì•Œë¦¼
    Agent-->>On: 6. ë™ê¸°í™” ì™„ë£Œ
```

#### DataSync ì„¤ì • ì˜ˆì‹œ


```python
# DataSync ì‘ì—… ìƒì„±
import boto3

datasync = boto3.client('datasync')

# ì†ŒìŠ¤ ìœ„ì¹˜ (ì˜¨í”„ë ˆë¯¸ìŠ¤ NFS)
source_location = datasync.create_location_nfs(
    ServerHostname='192.168.1.100',
    Subdirectory='/data',
    OnPremConfig={
        'AgentArns': ['arn:aws:datasync:...:agent/...']
    }
)

# ëŒ€ìƒ ìœ„ì¹˜ (S3)
destination_location = datasync.create_location_s3(
    S3BucketArn='arn:aws:s3:::my-bucket',
    Subdirectory='/backup'
)

# ë™ê¸°í™” ì‘ì—… ìƒì„±
task = datasync.create_task(
    SourceLocationArn=source_location['LocationArn'],
    DestinationLocationArn=destination_location['LocationArn'],
    Schedule={
        'ScheduleExpression': 'cron(0 2 * * ? *)'  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
    }
)

# âœ… ë§¤ì¼ ë°¤ ìë™ìœ¼ë¡œ ë°±ì—…ë©ë‹ˆë‹¤!
```

### ğŸ“¦ AWS Snow íŒ¨ë°€ë¦¬ (ë¬¼ë¦¬ì  ë°ì´í„° ì „ì†¡)


```mermaid
graph TB
    A[Snow íŒ¨ë°€ë¦¬] --> B[Snowcone<br/>8TB]
    A --> C[Snowball Edge<br/>80TB]
    A --> D[Snowmobile<br/>100PB]
    
    B -.->|í¬ê¸°| B1["ë…¸íŠ¸ë¶ë§Œí•œ í¬ê¸°<br/>íœ´ëŒ€ ê°€ëŠ¥<br/>ë“œë¡ , IoTìš©"]
    C -.->|í¬ê¸°| C1["ì—¬í–‰ê°€ë°© í¬ê¸°<br/>íŠ¸ëŸ­ ë°°ì†¡<br/>ë°ì´í„°ì„¼í„°ìš©"]
    D -.->|í¬ê¸°| D1["íŠ¸ëŸ­ í†µì§¸ë¡œ<br/>ì—‘ì‚¬ë°”ì´íŠ¸ê¸‰<br/>ì´ˆëŒ€í˜• ë§ˆì´ê·¸ë ˆì´ì…˜"]
    
    style B fill:#99ff99
    style C fill:#99ccff
    style D fill:#ff9999
```

#### Snow ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

**ì˜ˆì‹œ**: 100TBì˜ ì˜ìƒ íŒŒì¼ì„ AWSë¡œ ì˜®ê¸°ê¸°


```python
# âŒ ì¸í„°ë„·ìœ¼ë¡œ ì „ì†¡ ì‹œ
ì†ë„ = 100 Mbps  # ì¼ë°˜ì ì¸ ê¸°ì—… ì¸í„°ë„·
ìš©ëŸ‰ = 100 TB = 100,000 GB = 800,000,000 Mb
ì‹œê°„ = 800,000,000 / 100 = 8,000,000ì´ˆ = 92ì¼ ğŸŒ

# âœ… Snowball ì‚¬ìš© ì‹œ
ë°°ì†¡ = 2ì¼
ë³µì‚¬ = 1ì¼ (ë¡œì»¬ ê³ ì† ë„¤íŠ¸ì›Œí¬)
ë°˜ì†¡ = 2ì¼
ì´ ì‹œê°„ = 5ì¼ ğŸš€

# ğŸ’° ë¹„ìš© ë¹„êµ
ì¸í„°ë„·_ì „ì†¡ë¹„ = ì•½ $9,000 (S3 ì „ì†¡ ìš”ê¸ˆ)
Snowball_ë¹„ìš© = ì•½ $300 (10ì¼ ëŒ€ì—¬)
```

---

## 5. í˜„ì—… í™œìš© ê°€ì´ë“œ

### ğŸ† ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ TOP 3


```mermaid
pie title í˜„ì—…ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” AWS ìŠ¤í† ë¦¬ì§€
    "S3" : 50
    "EBS" : 30
    "EFS" : 15
    "ê¸°íƒ€" : 5
```

### ğŸ“± ì‹¤ì „ ì‚¬ìš© ì‚¬ë¡€

#### 1ï¸âƒ£ ìŠ¤íƒ€íŠ¸ì—… ì›¹ ì„œë¹„ìŠ¤


```mermaid
graph LR
    A[ì‚¬ìš©ì] -->|ì›¹ ì ‘ì†| B[CloudFront CDN]
    B --> C[S3<br/>ì •ì  ì½˜í…ì¸ ]
    B --> D[EC2<br/>ì›¹ ì„œë²„]
    D --> E[RDS<br/>ë°ì´í„°ë² ì´ìŠ¤]
    D --> F[S3<br/>ì‚¬ìš©ì ì—…ë¡œë“œ]
    
    style C fill:#ff9900
    style F fill:#ff9900
```

**ì‚¬ìš© ì„œë¹„ìŠ¤**:

- **S3**: ì´ë¯¸ì§€, CSS, JS íŒŒì¼ ì €ì¥
- **CloudFront**: ì „ ì„¸ê³„ ë¹ ë¥¸ ì „ì†¡
- **EBS**: ë°ì´í„°ë² ì´ìŠ¤ìš© ë””ìŠ¤í¬


```python
# ì‚¬ìš©ì í”„ë¡œí•„ ì‚¬ì§„ ì—…ë¡œë“œ ì²˜ë¦¬
def upload_profile_picture(user_id, file):
    s3 = boto3.client('s3')
    
    # íŒŒì¼ëª… ìƒì„± (ì¤‘ë³µ ë°©ì§€)
    filename = f"profiles/{user_id}/{uuid.uuid4()}.jpg"
    
    # S3ì— ì—…ë¡œë“œ
    s3.upload_fileobj(
        file,
        'my-app-bucket', filename, ExtraArgs={ 'ContentType': 'image/jpeg', 'CacheControl': 'max-age=31536000', # 1ë…„ ìºì‹± 'ACL': 'public-read' # ê³µê°œ ì½ê¸° } )
        
       # CloudFront URL ìƒì„±
url = f"https://cdn.myapp.com/{filename}"


       # âœ… ì‚¬ìš©ìì—ê²Œ URL ë°˜í™˜
return url
        
```


#### 2ï¸âƒ£ ë¯¸ë””ì–´ & ì—”í„°í…Œì¸ë¨¼íŠ¸
```mermaid
graph TB
    A[ì›ë³¸ ì˜ìƒ<br/>ì—…ë¡œë“œ] --> B[S3<br/>Standard]
    B --> C[Lambda<br/>íŠ¸ë¦¬ê±°]
    C --> D[MediaConvert<br/>ì¸ì½”ë”©]
    D --> E[S3<br/>Standard]
    D --> F[S3<br/>Glacier]
    E --> G[CloudFront<br/>ìŠ¤íŠ¸ë¦¬ë°]
    
    style B fill:#ff9900
    style E fill:#ff9900
    style F fill:#99ccff
```

**ì›Œí¬í”Œë¡œìš°**:
1. ê³ í™”ì§ˆ ì›ë³¸ â†’ S3 Standard
2. ìë™ ì¸ì½”ë”© (ì—¬ëŸ¬ í•´ìƒë„ ìƒì„±)
3. ìŠ¤íŠ¸ë¦¬ë°ìš© â†’ S3 Standard
4. ì›ë³¸ ë°±ì—… â†’ S3 Glacier (ì €ë ´í•œ ì¥ê¸° ë³´ê´€)
```python
# ì˜ìƒ ì—…ë¡œë“œ í›„ ìë™ ì²˜ë¦¬
def process_video(event, context):
    # S3 ì´ë²¤íŠ¸ì—ì„œ íŒŒì¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = event['Records'][0]['s3']['object']['key']
    
    # MediaConvert ì‘ì—… ìƒì„±
    mediaconvert = boto3.client('mediaconvert')
    
    job = mediaconvert.create_job(
        Role='arn:aws:iam::...:role/MediaConvertRole',
        Settings={
            'Inputs': [{
                'FileInput': f's3://{bucket}/{key}'
            }],
            'OutputGroups': [
                {
                    'Name': 'HLS ìŠ¤íŠ¸ë¦¬ë°',
                    'OutputGroupSettings': {
                        'Type': 'HLS_GROUP_SETTINGS',
                        'Destination': f's3://{bucket}/streaming/'
                    },
                    'Outputs': [
                        {'VideoDescription': {'Width': 1920, 'Height': 1080}},  # Full HD
                        {'VideoDescription': {'Width': 1280, 'Height': 720}},   # HD
                        {'VideoDescription': {'Width': 640, 'Height': 360}}     # SD
                    ]
                }
            ]
        }
    )
    
    # ì›ë³¸ì€ 30ì¼ í›„ Glacierë¡œ ì´ë™ (ìˆ˜ëª…ì£¼ê¸° ì •ì±…)
    # âœ… ìë™ìœ¼ë¡œ 3ê°€ì§€ í™”ì§ˆ ìƒì„±!
```

#### 3ï¸âƒ£ ë¹…ë°ì´í„° & ë¶„ì„
```mermaid
graph LR
    A[IoT ì„¼ì„œ] -->|ì‹¤ì‹œê°„| B[Kinesis]
    B --> C[Lambda]
    C --> D[S3 Data Lake]
    
    E[ì›¹ ë¡œê·¸] --> D
    F[ë°ì´í„°ë² ì´ìŠ¤<br/>ë°±ì—…] --> D
    
    D --> G[Athena<br/>SQL ì¿¼ë¦¬]
    D --> H[Glue<br/>ETL]
    H --> I[Redshift<br/>ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤]
    
    style D fill:#ff9900
```

**ë°ì´í„° ë ˆì´í¬ êµ¬ì¡°**:
```
s3://my-datalake/
â”œâ”€â”€ raw/                    # ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ 2025/10/15/
â”‚   â””â”€â”€ 2025/10/16/
â”œâ”€â”€ processed/              # ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â””â”€â”€ parquet/
â””â”€â”€ archive/                # ì•„ì¹´ì´ë¸Œ (Glacier)
    â””â”€â”€ 2024/
```
```python
# ë°ì´í„° ë ˆì´í¬ ì¿¼ë¦¬ (Athena)
import boto3

athena = boto3.client('athena')

# SQL ì¿¼ë¦¬ ì‹¤í–‰
response = athena.start_query_execution(
    QueryString="""
        SELECT date, count(*) as daily_users
        FROM user_activity
        WHERE year = 2025 AND month = 10
        GROUP BY date
        ORDER BY date
    """,
    QueryExecutionContext={
        'Database': 'my_datalake'
    },
    ResultConfiguration={
        'OutputLocation': 's3://my-results/athena/'
    }
)

# âœ… S3ì— ì €ì¥ëœ í˜íƒ€ë°”ì´íŠ¸ê¸‰ ë°ì´í„°ë¥¼ SQLë¡œ ë¶„ì„!
# ë¹„ìš©: ìŠ¤ìº”í•œ ë°ì´í„° 1TBë‹¹ $5
```

#### 4ï¸âƒ£ ê¸°ì—…ìš© ë°±ì—… & ì¬í•´ë³µêµ¬
```mermaid
graph TB
    A[ì˜¨í”„ë ˆë¯¸ìŠ¤<br/>ë°ì´í„°ì„¼í„°] -->|Storage Gateway| B[S3<br/>Standard]
    B -->|30ì¼ í›„| C[S3<br/>Standard-IA]
    C -->|90ì¼ í›„| D[S3 Glacier<br/>Flexible]
    D -->|365ì¼ í›„| E[S3 Glacier<br/>Deep Archive]
    
    B -.->|ë³µì œ| F[ë‹¤ë¥¸ ë¦¬ì „<br/>ì¬í•´ë³µêµ¬]
    
    style B fill:#ff6666
    style C fill:#ff9999
    style D fill:#99ccff
    style E fill:#6699ff
    style F fill:#99ff99
```
```python
# ë°±ì—… ì •ì±… ìë™í™”
backup_lifecycle = {
    "Rules": [
        {
            "Id": "ë°±ì—…-ë³´ê´€-ì •ì±…",
            "Status": "Enabled",
            "Filter": {
                "Prefix": "backups/"
            },
            "Transitions": [
                {
                    "Days": 30,
                    "StorageClass": "STANDARD_IA"  # ğŸ’° 50% ì ˆì•½
                },
                {
                    "Days": 90,
                    "StorageClass": "GLACIER_FLEXIBLE_RETRIEVAL"  # ğŸ’° 84% ì ˆì•½
                },
                {
                    "Days": 365,
                    "StorageClass": "DEEP_ARCHIVE"  # ğŸ’° 95% ì ˆì•½
                }
            ],
            "Expiration": {
                "Days": 2555  # 7ë…„ í›„ ì‚­ì œ (ê·œì • ì¤€ìˆ˜)
            }
        }
    ]
}

# âœ… 1ë…„ì¹˜ ë°±ì—… ë¹„ìš© ì˜ˆì‹œ
# Standard 1TB: $23/ì›” Ã— 12 = $276
# ì •ì±… ì ìš© ì‹œ: $276 â†’ $50 (82% ì ˆê°!)
```

### ğŸ’¡ í˜„ì—… ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

#### 1. ë¹„ìš© ìµœì í™” ì „ëµ
```mermaid
graph TD
    A[ë¹„ìš© ì ˆê° ì²´í¬ë¦¬ìŠ¤íŠ¸] --> B[ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìµœì í™”]
    A --> C[ìˆ˜ëª…ì£¼ê¸° ì •ì±… ì„¤ì •]
    A --> D[ë¶ˆí•„ìš”í•œ ë°ì´í„° ì‚­ì œ]
    A --> E[ì••ì¶• ë° ì¤‘ë³µ ì œê±°]
    
    B --> B1["âœ… Intelligent-Tiering ì‚¬ìš©<br/>âœ… ì ‘ê·¼ íŒ¨í„´ ë¶„ì„"]
    C --> C1["âœ… 30ì¼ í›„ IAë¡œ ì´ë™<br/>âœ… 90ì¼ í›„ Glacierë¡œ"]
    D --> D1["âœ… ë¯¸ì™„ë£Œ ë©€í‹°íŒŒíŠ¸ ì‚­ì œ<br/>âœ… ì˜¤ë˜ëœ ë²„ì „ ì •ë¦¬"]
    E --> E1["âœ… gzip ì••ì¶•<br/>âœ… ì¤‘ë³µ íŒŒì¼ ê²€ì‚¬"]
    
    style A fill:#ff6666
    style B fill:#99ff99
    style C fill:#99ccff
    style D fill:#ffcc99
    style E fill:#ff9999
```
```python
# ë¹„ìš© ìµœì í™” ìŠ¤í¬ë¦½íŠ¸
import boto3
from datetime import datetime, timedelta

s3 = boto3.client('s3')

def optimize_bucket_costs(bucket_name):
    """ë²„í‚· ë¹„ìš© ìµœì í™”"""
    
    # 1ï¸âƒ£ ë¯¸ì™„ë£Œ ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ ì‚­ì œ
    multipart_uploads = s3.list_multipart_uploads(Bucket=bucket_name)
    for upload in multipart_uploads.get('Uploads', []):
        # 7ì¼ ì´ìƒ ëœ ê²ƒë§Œ
        if upload['Initiated'] < datetime.now() - timedelta(days=7):
            s3.abort_multipart_upload(
                Bucket=bucket_name,
                Key=upload['Key'],
                UploadId=upload['UploadId']
            )
            print(f"âŒ ì‚­ì œ: {upload['Key']}")
    
    # 2ï¸âƒ£ ì˜¤ë˜ëœ ë²„ì „ ì‚­ì œ (90ì¼ ì´ìƒ)
    versions = s3.list_object_versions(Bucket=bucket_name)
    for version in versions.get('Versions', []):
        if not version['IsLatest']:
            age = datetime.now() - version['LastModified'].replace(tzinfo=None)
            if age.days > 90:
                s3.delete_object(
                    Bucket=bucket_name,
                    Key=version['Key'],
                    VersionId=version['VersionId']
                )
                print(f"ğŸ—‘ï¸ ì´ì „ ë²„ì „ ì‚­ì œ: {version['Key']}")
    
    # 3ï¸âƒ£ Intelligent-Tiering ì„¤ì •
    s3.put_bucket_intelligent_tiering_configuration(
        Bucket=bucket_name,
        Id='AutoOptimize',
        IntelligentTieringConfiguration={
            'Id': 'AutoOptimize',
            'Status': 'Enabled',
            'Tierings': [
                {
                    'Days': 90,
                    'AccessTier': 'ARCHIVE_ACCESS'
                },
                {
                    'Days': 180,
                    'AccessTier': 'DEEP_ARCHIVE_ACCESS'
                }
            ]
        }
    )
    
    print("âœ… ë¹„ìš© ìµœì í™” ì™„ë£Œ!")

# ì‹¤í–‰
optimize_bucket_costs('my-production-bucket')
```

#### 2. ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸
```mermaid
graph LR
    A[ë³´ì•ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸] --> B[âœ… ì•”í˜¸í™”]
    A --> C[âœ… ì ‘ê·¼ ì œì–´]
    A --> D[âœ… ë¡œê¹…]
    A --> E[âœ… ë°±ì—…]
    
    B --> B1["ì „ì†¡: TLS<br/>ì €ì¥: SSE-S3/KMS"]
    C --> C1["IAM ì •ì±…<br/>ë²„í‚· ì •ì±…<br/>MFA Delete"]
    D --> D1["CloudTrail<br/>S3 Access Log<br/>GuardDuty"]
    E --> E1["ë²„ì „ ê´€ë¦¬<br/>ë³µì œ<br/>ë°±ì—… Vault"]
    
    style A fill:#ff6666
```
```python
# ë³´ì•ˆ ê°•í™” ìŠ¤í¬ë¦½íŠ¸
def secure_bucket(bucket_name):
    """ë²„í‚· ë³´ì•ˆ ê°•í™”"""
    s3 = boto3.client('s3')
    
    # 1ï¸âƒ£ í¼ë¸”ë¦­ ì•¡ì„¸ìŠ¤ ì°¨ë‹¨
    s3.put_public_access_block(
        Bucket=bucket_name,
        PublicAccessBlockConfiguration={
            'BlockPublicAcls': True,
            'IgnorePublicAcls': True,
            'BlockPublicPolicy': True,
            'RestrictPublicBuckets': True
        }
    )
    print("âœ… í¼ë¸”ë¦­ ì•¡ì„¸ìŠ¤ ì°¨ë‹¨")
    
    # 2ï¸âƒ£ ì•”í˜¸í™” í™œì„±í™” (ê¸°ë³¸ ì•”í˜¸í™”)
    s3.put_bucket_encryption(
        Bucket=bucket_name,
        ServerSideEncryptionConfiguration={
            'Rules': [{
                'ApplyServerSideEncryptionByDefault': {
                    'SSEAlgorithm': 'AES256'  # SSE-S3
                },
                'BucketKeyEnabled': True  # ë¹„ìš© ì ˆê°
            }]
        }
    )
    print("âœ… ì•”í˜¸í™” í™œì„±í™”")
    
    # 3ï¸âƒ£ ë²„ì „ ê´€ë¦¬ í™œì„±í™”
    s3.put_bucket_versioning(
        Bucket=bucket_name,
        VersioningConfiguration={'Status': 'Enabled'}
    )
    print("âœ… ë²„ì „ ê´€ë¦¬ í™œì„±í™”")
    
    # 4ï¸âƒ£ ë¡œê¹… í™œì„±í™”
    s3.put_bucket_logging(
        Bucket=bucket_name,
        BucketLoggingStatus={
            'LoggingEnabled': {
                'TargetBucket': f'{bucket_name}-logs',
                'TargetPrefix': 'access-logs/'
            }
        }
    )
    print("âœ… ì•¡ì„¸ìŠ¤ ë¡œê¹… í™œì„±í™”")
    
    # 5ï¸âƒ£ ê°ì²´ ì ê¸ˆ (ê·œì • ì¤€ìˆ˜ìš©)
    s3.put_object_lock_configuration(
        Bucket=bucket_name,
        ObjectLockConfiguration={
            'ObjectLockEnabled': 'Enabled',
            'Rule': {
                'DefaultRetention': {
                    'Mode': 'COMPLIANCE',  # ë˜ëŠ” 'GOVERNANCE'
                    'Days': 365  # 1ë…„ê°„ ì‚­ì œ ë¶ˆê°€
                }
            }
        }
    )
    print("âœ… ê°ì²´ ì ê¸ˆ ì„¤ì •")

# ì‹¤í–‰
secure_bucket('my-sensitive-data')
```

#### 3. ì„±ëŠ¥ ìµœì í™”
```mermaid
graph TB
    A[ì„±ëŠ¥ ìµœì í™”] --> B[ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ]
    A --> C[Transfer Acceleration]
    A --> D[CloudFront CDN]
    A --> E[S3 Select]
    
    B -.->|ì–¸ì œ?| B1["100MB ì´ìƒ íŒŒì¼<br/>ë³‘ë ¬ ì—…ë¡œë“œë¡œ 10ë°° ë¹ ë¦„"]
    C -.->|ì–¸ì œ?| C1["ê¸€ë¡œë²Œ ì‚¬ìš©ì<br/>50% ì´ìƒ ì†ë„ í–¥ìƒ"]
    D -.->|ì–¸ì œ?| D1["ì •ì  ì½˜í…ì¸ <br/>ìºì‹±ìœ¼ë¡œ ì§€ì—° ê°ì†Œ"]
    E -.->|ì–¸ì œ?| E1["ëŒ€ìš©ëŸ‰ JSON/CSV<br/>í•„í„°ë§ìœ¼ë¡œ ë¹„ìš© ì ˆê°"]
    
    style A fill:#ff6666
    style B fill:#99ff99
    style C fill:#99ccff
    style D fill:#ffcc99
    style E fill:#ff9999
```
```python
# ì„±ëŠ¥ ìµœì í™” ì˜ˆì‹œ

# 1ï¸âƒ£ ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ (ëŒ€ìš©ëŸ‰ íŒŒì¼)
def upload_large_file(file_path, bucket, key):
    """100MB ì´ìƒ íŒŒì¼ ê³ ì† ì—…ë¡œë“œ"""
    import boto3
    from boto3.s3.transfer import TransferConfig
    
    # ì„¤ì •: 10MB ë‹¨ìœ„ë¡œ ë¶„í• , 10ê°œ ë³‘ë ¬
    config = TransferConfig(
        multipart_threshold=1024 * 1024 * 10,  # 10MB
        max_concurrency=10,
        multipart_chunksize=1024 * 1024 * 10,
        use_threads=True
    )
    
    s3 = boto3.client('s3')
    s3.upload_file(
        file_path, bucket, key,
        Config=config,
        Callback=ProgressPercentage(file_path)  # ì§„í–‰ë¥  í‘œì‹œ
    )
    
    # âœ… 1GB íŒŒì¼ ì—…ë¡œë“œ: 10ë¶„ â†’ 1ë¶„!

# 2ï¸âƒ£ S3 Select (ë°ì´í„° í•„í„°ë§)
def query_large_csv(bucket, key):
    """ëŒ€ìš©ëŸ‰ CSVì—ì„œ í•„ìš”í•œ ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ê¸°"""
    s3 = boto3.client('s3')
    
    response = s3.select_object_content(
        Bucket=bucket,
        Key=key,
        Expression="SELECT * FROM s3object s WHERE s.age > 30",
        ExpressionType='SQL',
        InputSerialization={
            'CSV': {'FileHeaderInfo': 'USE'}
        },
        OutputSerialization={
            'JSON': {}
        }
    )
    
    # ê²°ê³¼ë§Œ ë°›ì•„ì˜¤ê¸°
    for event in response['Payload']:
        if 'Records' in event:
            print(event['Records']['Payload'].decode())
    
    # âœ… 1GB CSV â†’ 10MBë§Œ ì „ì†¡ (90% ì ˆê°!)

# 3ï¸âƒ£ CloudFront ìºì‹±
cloudfront_config = {
    "OriginConfig": {
        "S3OriginConfig": {
            "OriginAccessIdentity": "..."  # S3 ì§ì ‘ ì ‘ê·¼ ì°¨ë‹¨
        }
    },
    "CacheBehaviors": {
        "PathPattern": "images/*",
        "ViewerProtocolPolicy": "redirect-to-https",
        "Compress": True,  # ìë™ ì••ì¶•
        "CachePolicyId": "658327ea-f89d-4fab-a63d-7e88639e58f6"  # CachingOptimized
    }
}
# âœ… ì´ë¯¸ì§€ ë¡œë”©: 2ì´ˆ â†’ 0.1ì´ˆ!
```

### ğŸ“Š ì‹¤ì œ ë¹„ìš© ë¹„êµ

#### ì‹œë‚˜ë¦¬ì˜¤: ìŠ¤íƒ€íŠ¸ì—… ì›¹ ì„œë¹„ìŠ¤ (ì›” íŠ¸ë˜í”½ 1TB)
```mermaid
graph TB
    A[ì›”ê°„ ë¹„ìš© ë¹„êµ] --> B[ì˜¨í”„ë ˆë¯¸ìŠ¤<br/>$1,500]
    A --> C[AWS ìµœì í™” ì „<br/>$500]
    A --> D[AWS ìµœì í™” í›„<br/>$150]
    
    B -.->|í•­ëª©| B1["ì„œë²„: $800<br/>ìŠ¤í† ë¦¬ì§€: $400<br/>ë„¤íŠ¸ì›Œí¬: $300"]
    C -.->|í•­ëª©| C1["S3 Standard: $230<br/>EC2: $200<br/>ë°ì´í„° ì „ì†¡: $70"]
    D -.->|í•­ëª©| D1["S3 IA/Glacier: $50<br/>EC2: $80<br/>CloudFront: $20"]
    
    style B fill:#ff6666
    style C fill:#ffcc99
    style D fill:#99ff99
```

**ìµœì í™” ì „ëµ**:
```python
# ë¹„ìš© ë¶„ì„ ë° ìµœì í™”
monthly_costs = {
    "ìµœì í™” ì „": {
        "S3_Standard": 230,
        "EC2_m5.large": 200,
        "ë°ì´í„°_ì „ì†¡": 70,
        "í•©ê³„": 500
    },
    "ìµœì í™” í›„": {
        "S3_Intelligent_Tiering": 50,  # 78% ì ˆê°
        "EC2_t3.medium_Spot": 80,      # 60% ì ˆê°
        "CloudFront_ìºì‹±": 20,         # 71% ì ˆê°
        "í•©ê³„": 150
    }
}

ì ˆê°ë¥  = (500 - 150) / 500 * 100
print(f"ğŸ’° ì›” ${500-150} ì ˆê° ({ì ˆê°ë¥ }%)")
print(f"ğŸ’° ì—°ê°„ ${(500-150)*12} ì ˆê°!")

# ê²°ê³¼: ì—°ê°„ $4,200 ì ˆê°! ğŸ‰
```

### ğŸ“ í•™ìŠµ ë¡œë“œë§µ
```mermaid
graph TD
    A[AWS ìŠ¤í† ë¦¬ì§€ í•™ìŠµ ë¡œë“œë§µ] --> B[1ë‹¨ê³„: ê¸°ì´ˆ]
    A --> C[2ë‹¨ê³„: ì¤‘ê¸‰]
    A --> D[3ë‹¨ê³„: ê³ ê¸‰]
    A --> E[4ë‹¨ê³„: ì „ë¬¸ê°€]
    
    B --> B1["âœ… S3 ê¸°ë³¸ ì‚¬ìš©<br/>âœ… ë²„í‚· ìƒì„±/ì—…ë¡œë“œ<br/>âœ… ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ì´í•´"]
    C --> C1["âœ… ìˆ˜ëª…ì£¼ê¸° ì •ì±…<br/>âœ… ë²„ì „ ê´€ë¦¬<br/>âœ… CloudFront ì—°ë™"]
    D --> D1["âœ… ë¹„ìš© ìµœì í™”<br/>âœ… ë³´ì•ˆ ê°•í™”<br/>âœ… DataSync/Snow"]
    E --> E1["âœ… ëŒ€ê·œëª¨ ì•„í‚¤í…ì²˜<br/>âœ… ë°ì´í„° ë ˆì´í¬<br/>âœ… ë©€í‹° ë¦¬ì „ ë³µì œ"]
    
    style A fill:#ff6666
    style B fill:#99ff99
    style C fill:#99ccff
    style D fill:#ffcc99
    style E fill:#ff9999
```

### ğŸ› ï¸ ì‹¤ìŠµ í”„ë¡œì íŠ¸ ì•„ì´ë””ì–´

#### í”„ë¡œì íŠ¸ 1: ê°œì¸ í´ë¼ìš°ë“œ í¬í†  ê°¤ëŸ¬ë¦¬
```python
# ê°„ë‹¨í•œ ì‚¬ì§„ ê°¤ëŸ¬ë¦¬ ë°±ì—”ë“œ
from flask import Flask, request, jsonify
import boto3
import uuid

app = Flask(__name__)
s3 = boto3.client('s3')
BUCKET = 'my-photo-gallery'

@app.route('/upload', methods=['POST'])
def upload_photo():
    """ì‚¬ì§„ ì—…ë¡œë“œ"""
    file = request.files['photo']
    filename = f"photos/{uuid.uuid4()}.jpg"
    
    # S3ì— ì—…ë¡œë“œ
    s3.upload_fileobj(
        file,
        BUCKET,
        filename,
        ExtraArgs={
            'ContentType': 'image/jpeg',
            'Metadata': {
                'uploaded-by': request.form['user_id'],
                'timestamp': str(datetime.now())
            }
        }
    )
    
    # ì¸ë„¤ì¼ ìƒì„± (Lambda íŠ¸ë¦¬ê±°)
    # CloudFront URL ë°˜í™˜
    url = f"https://cdn.mygallery.com/{filename}"
    return jsonify({'url': url})

@app.route('/photos', methods=['GET'])
def list_photos():
    """ì‚¬ì§„ ëª©ë¡"""
    response = s3.list_objects_v2(
        Bucket=BUCKET,
        Prefix='photos/'
    )
    
    photos = [{
        'url': f"https://cdn.mygallery.com/{obj['Key']}",
        'size': obj['Size'],
        'date': obj['LastModified'].isoformat()
    } for obj in response.get('Contents', [])]
    
    return jsonify(photos)

# âœ… ì‹¤í–‰: flask run
```

#### í”„ë¡œì íŠ¸ 2: ë¡œê·¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸
```mermaid
graph LR
    A[ì›¹ ì„œë²„] -->|ë¡œê·¸ ìƒì„±| B[S3 raw/]
    B -->|Glue Crawler| C[Data Catalog]
    C --> D[Athena]
    D -->|SQL ë¶„ì„| E[QuickSight<br/>ëŒ€ì‹œë³´ë“œ]
    
    B -->|30ì¼ í›„| F[S3 Glacier]
    
    style B fill:#ff9900
    style F fill:#99ccff
```
```python
# ë¡œê·¸ ë¶„ì„ ìë™í™”
import boto3
from datetime import datetime

def analyze_logs():
    """ë§¤ì¼ ë¡œê·¸ ë¶„ì„"""
    athena = boto3.client('athena')
    
    # ì–´ì œ ë¡œê·¸ ë¶„ì„
    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y/%m/%d')
    
    query = f"""
    SELECT
        hour,
        COUNT(*) as requests,
        AVG(response_time) as avg_response_time,
        SUM(CASE WHEN status_code >= 500 THEN 1 ELSE 0 END) as errors
    FROM
        access_logs
    WHERE
        date = '{yesterday}'
    GROUP BY
        hour
    ORDER BY
        hour
    """
    
    # ì¿¼ë¦¬ ì‹¤í–‰
    response = athena.start_query_execution(
        QueryString=query,
        QueryExecutionContext={'Database': 'logs'},
        ResultConfiguration={
            'OutputLocation': 's3://my-logs/analysis/'
        }
    )
    
    # âœ… ê²°ê³¼ëŠ” S3ì— ìë™ ì €ì¥ë˜ê³  QuickSightë¡œ ì‹œê°í™”!
    return response['QueryExecutionId']

# Lambdaë¡œ ë§¤ì¼ ìë™ ì‹¤í–‰
```

### ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ
```python
# CloudWatch ì•ŒëŒ ì„¤ì •
import boto3

cloudwatch = boto3.client('cloudwatch')

# S3 ë¹„ìš© ì•ŒëŒ
cloudwatch.put_metric_alarm(
    AlarmName='S3-ê³ ì•¡-ì²­êµ¬-ì•ŒëŒ',
    ComparisonOperator='GreaterThanThreshold',
    EvaluationPeriods=1,
    MetricName='EstimatedCharges',
    Namespace='AWS/Billing',
    Period=86400,  # 1ì¼
    Statistic='Maximum',
    Threshold=100.0,  # $100 ì´ˆê³¼ ì‹œ
    ActionsEnabled=True,
    AlarmActions=[
        'arn:aws:sns:ap-northeast-2:...:billing-alerts'
    ],
    AlarmDescription='S3 ë¹„ìš©ì´ $100 ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!'
)

# S3 ë²„í‚· í¬ê¸° ëª¨ë‹ˆí„°ë§
cloudwatch.put_metric_alarm(
    AlarmName='S3-ë²„í‚·-ìš©ëŸ‰-ì•ŒëŒ',
    ComparisonOperator='GreaterThanThreshold',
    EvaluationPeriods=1,
    MetricName='BucketSizeBytes',
    Namespace='AWS/S3',
    Period=86400,
    Statistic='Average',
    Threshold=1099511627776,  # 1TB
    Dimensions=[
        {
            'Name': 'BucketName',
            'Value': 'my-production-bucket'
        },
        {
            'Name': 'StorageType',
            'Value': 'StandardStorage'
        }
    ]
)

# âœ… ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì´ë©”ì¼/SMS ì•Œë¦¼!
```

### ğŸ¯ ìµœì¢… ì •ë¦¬: ì„ íƒ ê°€ì´ë“œ
```mermaid
graph TD
    Start[ë°ì´í„° ì €ì¥ í•„ìš”] --> Q1{ì–´ë–¤ ë°ì´í„°?}
    
    Q1 -->|íŒŒì¼| Q2{ëˆ„ê°€ ì‚¬ìš©?}
    Q1 -->|ë””ìŠ¤í¬| EBS[EBS ì¶”ì²œ]
    Q1 -->|ë°±ì—…/ì•„ì¹´ì´ë¸Œ| S3[S3 Glacier ì¶”ì²œ]
    
    Q2 -->|í•œ ì„œë²„ë§Œ| EBS
    Q2 -->|ì—¬ëŸ¬ ì„œë²„| Q3{OS?}
    
    Q3 -->|Linux| EFS[EFS ì¶”ì²œ]
    Q3 -->|Windows| FSx[FSx for Windows ì¶”ì²œ]
    Q3 -->|ê³ ì„±ëŠ¥ í•„ìš”| Lustre[FSx for Lustre ì¶”ì²œ]
    
    style EBS fill:#ffcc99
    style S3 fill:#ff9900
    style EFS fill:#99ff99
    style FSx fill:#99ccff
    style Lustre fill:#ff9999
```

### ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

**ê³µì‹ ë¬¸ì„œ**:
- [AWS S3 ë¬¸ì„œ](https://docs.aws.amazon.com/s3/)
- [AWS ìŠ¤í† ë¦¬ì§€ ë¸”ë¡œê·¸](https://aws.amazon.com/blogs/storage/)

**ì‹¤ìŠµ í™˜ê²½**:
```bash
# AWS CLI ì„¤ì¹˜ (Mac)
brew install awscli

# ì„¤ì •
aws configure
# AWS Access Key ID: [ì…ë ¥]
# AWS Secret Access Key: [ì…ë ¥]
# Default region: ap-northeast-2
# Default output format: json

# S3 ë²„í‚· ìƒì„±
aws s3 mb s3://my-first-bucket-20251015

# íŒŒì¼ ì—…ë¡œë“œ
aws s3 cp photo.jpg s3://my-first-bucket-20251015/

# íŒŒì¼ ëª©ë¡
aws s3 ls s3://my-first-bucket-20251015/

# âœ… ì´ì œ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ìš”!
```

---

## ğŸ‰ ë§ˆë¬´ë¦¬

### í•µì‹¬ í¬ì¸íŠ¸ ìš”ì•½

1. **S3**: ê°€ì¥ ë§ì´ ì‚¬ìš© (50%), ë°±ì—…/ì›¹ ì½˜í…ì¸ /ë°ì´í„° ë ˆì´í¬
2. **EBS**: EC2 ë””ìŠ¤í¬, ë°ì´í„°ë² ì´ìŠ¤ìš©
3. **EFS**: ì—¬ëŸ¬ ì„œë²„ê°€ íŒŒì¼ ê³µìœ 
4. **ë¹„ìš© ìµœì í™”**: ìˆ˜ëª…ì£¼ê¸° ì •ì±…ìœ¼ë¡œ 70-90% ì ˆê° ê°€ëŠ¥
5. **ë³´ì•ˆ**: ì•”í˜¸í™” + ë²„ì „ ê´€ë¦¬ + ë¡œê¹… í•„ìˆ˜

### ë‹¤ìŒ ë‹¨ê³„
```mermaid
graph LR
    A[ì§€ê¸ˆ] --> B[S3 ë²„í‚· ë§Œë“¤ê¸°]
    B --> C[íŒŒì¼ ì—…ë¡œë“œ/ë‹¤ìš´ë¡œë“œ]
    C --> D[ìˆ˜ëª…ì£¼ê¸° ì •ì±… ì„¤ì •]
    D --> E[Lambda ì—°ë™]
    E --> F[ì‹¤ì „ í”„ë¡œì íŠ¸]
    
    style A fill:#ff6666
    style F fill:#99ff99
```

**ì§ì ‘ í•´ë³´ì„¸ìš”!** ğŸš€
```python
# ì—¬ëŸ¬ë¶„ì˜ ì²« S3 í”„ë¡œì íŠ¸
import boto3

# TODO: ì—¬ê¸°ì— ì—¬ëŸ¬ë¶„ë§Œì˜ ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ì„¸ìš”!
s3 = boto3.client('s3')

# 1. ë²„í‚· ìƒì„±
# 2. íŒŒì¼ ì—…ë¡œë“œ
# 3. ê³µê°œ URL ìƒì„±
# 4. ìˆ˜ëª…ì£¼ê¸° ì •ì±… ì ìš©

# ì™„ì„±í•˜ë©´ ì—¬ëŸ¬ë¶„ì€ AWS ìŠ¤í† ë¦¬ì§€ ì „ë¬¸ê°€! ğŸ“
```

---

**Happy Cloud Storage! â˜ï¸**
